{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "\n",
    "import SupervisedLearning.Experiments.CNNExperments as ce\n",
    "import SupervisedLearning.Experiments.GetData as gd\n",
    "import SupervisedLearning.NeuralNetworks.Conv as cnn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Err: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = gd.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = gd.get_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cnn.ConvolutionalNeuralNetwork(10)\n",
    "classifier_name = 'CNN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 48, 48, 75)        750       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 48, 48, 75)        300       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 24, 24, 75)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 50)        33800     \n_________________________________________________________________\ndropout (Dropout)            (None, 24, 24, 50)        0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 24, 24, 50)        200       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 50)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 12, 25)        11275     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 12, 12, 25)        100       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 25)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 900)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               461312    \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 775,523\nTrainable params: 775,223\nNon-trainable params: 300\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Currently logged in as: samfh (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">sandy-galaxy-52</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/ygpdxpt6\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/ygpdxpt6</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182156-ygpdxpt6</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 4s 470us/sample - loss: 0.7236 - accuracy: 0.7598 - val_loss: 0.5708 - val_accuracy: 0.8142\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.1087 - accuracy: 0.9671 - val_loss: 0.3838 - val_accuracy: 0.9123\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0752 - accuracy: 0.9822 - val_loss: 0.3327 - val_accuracy: 0.9195\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0456 - accuracy: 0.9897 - val_loss: 0.8639 - val_accuracy: 0.8824\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0522 - accuracy: 0.9897 - val_loss: 1.5997 - val_accuracy: 0.8380\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0500 - accuracy: 0.9911 - val_loss: 1.0722 - val_accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0445 - accuracy: 0.9929 - val_loss: 1.0525 - val_accuracy: 0.8854\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0301 - accuracy: 0.9942 - val_loss: 0.5909 - val_accuracy: 0.9319\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0362 - accuracy: 0.9947 - val_loss: 0.6512 - val_accuracy: 0.9391\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0514 - accuracy: 0.9937 - val_loss: 1.3763 - val_accuracy: 0.9216\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0286 - accuracy: 0.9964 - val_loss: 0.6415 - val_accuracy: 0.9154\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0275 - accuracy: 0.9963 - val_loss: 0.9573 - val_accuracy: 0.9102\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0154 - accuracy: 0.9975 - val_loss: 3.0256 - val_accuracy: 0.8421\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0234 - accuracy: 0.9962 - val_loss: 0.4128 - val_accuracy: 0.9567\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0253 - accuracy: 0.9971 - val_loss: 0.4456 - val_accuracy: 0.9659\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0105 - accuracy: 0.9977 - val_loss: 1.0075 - val_accuracy: 0.9216\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0168 - accuracy: 0.9978 - val_loss: 1.1280 - val_accuracy: 0.9432\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0302 - accuracy: 0.9974 - val_loss: 1.4363 - val_accuracy: 0.9164\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.4187 - val_accuracy: 0.9649\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0141 - accuracy: 0.9986 - val_loss: 2.2780 - val_accuracy: 0.8772\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0187 - accuracy: 0.9979 - val_loss: 0.4444 - val_accuracy: 0.9742\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0302 - accuracy: 0.9968 - val_loss: 1.0792 - val_accuracy: 0.9288\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.8621 - val_accuracy: 0.8978\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.5142 - val_accuracy: 0.9628\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0146 - accuracy: 0.9989 - val_loss: 1.5692 - val_accuracy: 0.9329\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0151 - accuracy: 0.9982 - val_loss: 1.2328 - val_accuracy: 0.9556\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0083 - accuracy: 0.9991 - val_loss: 1.1561 - val_accuracy: 0.9577\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0206 - accuracy: 0.9985 - val_loss: 2.0596 - val_accuracy: 0.9288\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0332 - accuracy: 0.9974 - val_loss: 3.7101 - val_accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0124 - accuracy: 0.9986 - val_loss: 1.8086 - val_accuracy: 0.8885\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0115 - accuracy: 0.9991 - val_loss: 0.8263 - val_accuracy: 0.9494\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.5579 - val_accuracy: 0.9690\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0241 - accuracy: 0.9983 - val_loss: 3.9961 - val_accuracy: 0.7750\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0207 - accuracy: 0.9979 - val_loss: 1.4976 - val_accuracy: 0.9009\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0111 - accuracy: 0.9990 - val_loss: 3.2564 - val_accuracy: 0.8586\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0165 - accuracy: 0.9991 - val_loss: 1.2321 - val_accuracy: 0.9267\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0131 - accuracy: 0.9994 - val_loss: 0.9382 - val_accuracy: 0.9546\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0151 - accuracy: 0.9986 - val_loss: 1.0103 - val_accuracy: 0.9577\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 182us/sample - loss: 0.0085 - accuracy: 0.9990 - val_loss: 1.4694 - val_accuracy: 0.9525\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0174 - accuracy: 0.9982 - val_loss: 1.2082 - val_accuracy: 0.9484\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 182us/sample - loss: 0.0053 - accuracy: 0.9992 - val_loss: 1.3745 - val_accuracy: 0.9505\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0093 - accuracy: 0.9986 - val_loss: 2.4831 - val_accuracy: 0.8927\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 0.0257 - accuracy: 0.9979 - val_loss: 2.1580 - val_accuracy: 0.9185\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0149 - accuracy: 0.9989 - val_loss: 3.0116 - val_accuracy: 0.8689\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0179 - accuracy: 0.9985 - val_loss: 1.0826 - val_accuracy: 0.9432\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 2.0744 - val_accuracy: 0.9185\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0035 - accuracy: 0.9994 - val_loss: 2.4434 - val_accuracy: 0.9247\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 1s 172us/sample - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.7002 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 174us/sample - loss: 0.0053 - accuracy: 0.9991 - val_loss: 3.6528 - val_accuracy: 0.8596\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 1s 165us/sample - loss: 0.0131 - accuracy: 0.9987 - val_loss: 1.7077 - val_accuracy: 0.9298\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 5128<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182156-ygpdxpt6\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182156-ygpdxpt6\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.01315</td></tr><tr><td>accuracy</td><td>0.99874</td></tr><tr><td>val_loss</td><td>1.70767</td></tr><tr><td>val_accuracy</td><td>0.92982</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>85</td></tr><tr><td>_timestamp</td><td>1607019801</td></tr><tr><td>best_val_loss</td><td>0.33275</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▂▁▂▂▂▆▁▂▃▃▁▁▂▂▁▃▃▄▇▂▁█▃▃▂▂▃▃▅▄▆▄▅▂▄</td></tr><tr><td>val_accuracy</td><td>▂▆▆▅▅▅▇▇▆▆▃▇▆▇▆██▆▅█▇▇▆▄▇█▁▅▆▇▇▇▇▅▆▄▆▆█▆</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">sandy-galaxy-52</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/ygpdxpt6\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/ygpdxpt6</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">robust-fog-53</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3j5tt27q\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3j5tt27q</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182326-3j5tt27q</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0954 - accuracy: 0.9951 - val_loss: 8.2835e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 0.0271 - accuracy: 0.9981 - val_loss: 7.6957e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0212 - accuracy: 0.9977 - val_loss: 0.0014 - val_accuracy: 0.9990\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0341 - accuracy: 0.9969 - val_loss: 1.4105e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0169 - accuracy: 0.9990 - val_loss: 0.0104 - val_accuracy: 0.9979\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.2427 - val_accuracy: 0.9814\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0146 - accuracy: 0.9993 - val_loss: 0.1203 - val_accuracy: 0.9907\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.2373 - val_accuracy: 0.9866\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 182us/sample - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.2239 - val_accuracy: 0.9886\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0283 - val_accuracy: 0.9948\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0114 - accuracy: 0.9992 - val_loss: 8.6923e-04 - val_accuracy: 0.9990\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0175 - accuracy: 0.9993 - val_loss: 0.0500 - val_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.0564 - val_accuracy: 0.9897\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0198 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0066 - accuracy: 0.9993 - val_loss: 1.5475e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0160 - accuracy: 0.9993 - val_loss: 0.0758 - val_accuracy: 0.9886\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.1012 - val_accuracy: 0.9959\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0195 - val_accuracy: 0.9969\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.1619 - val_accuracy: 0.9876\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0758 - val_accuracy: 0.9948\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0099 - val_accuracy: 0.9990\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1479 - val_accuracy: 0.9897\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.0571 - val_accuracy: 0.9928\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 1s 172us/sample - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0585 - val_accuracy: 0.9979\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.0108 - val_accuracy: 0.9990\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.2693 - val_accuracy: 0.9897\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.1585 - val_accuracy: 0.9886\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9979\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0135 - val_accuracy: 0.9969\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.0199 - val_accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9959\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0115 - accuracy: 0.9997 - val_loss: 0.7270 - val_accuracy: 0.9659\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0284 - accuracy: 0.9991 - val_loss: 0.2103 - val_accuracy: 0.9845\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0192 - val_accuracy: 0.9979\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0651 - val_accuracy: 0.9897\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 9.4904e-08 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9866\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.0254 - val_accuracy: 0.9979\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0158 - val_accuracy: 0.9938\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 178us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0688 - val_accuracy: 0.9917\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 1.2816e-05 - accuracy: 1.0000 - val_loss: 1.9919e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 1s 172us/sample - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.2950 - val_accuracy: 0.9804\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 7.2694e-04 - accuracy: 0.9998 - val_loss: 0.0969 - val_accuracy: 0.9835\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1855 - val_accuracy: 0.9876\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0308 - val_accuracy: 0.9948\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9938\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 1s 169us/sample - loss: 4.4700e-04 - accuracy: 0.9999 - val_loss: 9.1751e-04 - val_accuracy: 0.9990\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0118 - accuracy: 0.9995 - val_loss: 0.1424 - val_accuracy: 0.9897\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0146 - accuracy: 0.9994 - val_loss: 0.1879 - val_accuracy: 0.9876\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 1s 167us/sample - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0298 - val_accuracy: 0.9959\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1844 - val_accuracy: 0.9794\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 35108<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182326-3j5tt27q\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182326-3j5tt27q\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0054</td></tr><tr><td>accuracy</td><td>0.99966</td></tr><tr><td>val_loss</td><td>0.18441</td></tr><tr><td>val_accuracy</td><td>0.97936</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1607019885</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>14</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▃▄▂▂▁▂▂▂▂▂▂▁▁▁▁▁▂▁▁▂▂▁▁▂▃▁▁▁▁▁▂▁▁▁▁▂▂▁</td></tr><tr><td>accuracy</td><td>▁▅▅▄▆▇▇▇▇▇▇▇▇█▇█▇▇█▇▇▇▇███▇██▇██▇████▇▇█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▃▂▃▃▁▁▂▁▂▂▁▃▁▂▂▂▄▃▁▁▂█▃▁▃▁▁▂▄▂▃▁▁▂▃▃</td></tr><tr><td>val_accuracy</td><td>████▄▆▅▆█▇▆█▆▇▇▅█▆▇█▆▆█▇▇▁▅█▅█▇▆▄▅▅▇█▆▅▄</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">robust-fog-53</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3j5tt27q\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3j5tt27q</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">dark-voice-54</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/6qlwesyu\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/6qlwesyu</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182448-6qlwesyu</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0185 - accuracy: 0.9986 - val_loss: 0.0080 - val_accuracy: 0.9990\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0252 - accuracy: 0.9989 - val_loss: 0.0893 - val_accuracy: 0.9876\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 0.0131 - accuracy: 0.9991 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 0.0213 - accuracy: 0.9982 - val_loss: 6.1511e-10 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0047 - accuracy: 0.9998 - val_loss: 1.0652e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0051 - accuracy: 0.9997 - val_loss: 2.8295e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0023 - accuracy: 0.9997 - val_loss: 4.0597e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 5.0687e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 1s 167us/sample - loss: 0.0116 - accuracy: 0.9987 - val_loss: 1.4469e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 5.0198e-04 - accuracy: 0.9999 - val_loss: 4.2042e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0053 - accuracy: 0.9999 - val_loss: 2.4605e-10 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 1s 172us/sample - loss: 3.7559e-06 - accuracy: 1.0000 - val_loss: 7.6179e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0184 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9990\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0189 - val_accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.0294 - val_accuracy: 0.9979\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 0.0133 - accuracy: 0.9987 - val_loss: 0.0556 - val_accuracy: 0.9979\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0153 - val_accuracy: 0.9979\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 172us/sample - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.3339e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 1.7283e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9979\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0125 - accuracy: 0.9992 - val_loss: 0.0234 - val_accuracy: 0.9969\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 1s 168us/sample - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.1024 - val_accuracy: 0.9866\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0144 - accuracy: 0.9991 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0095 - accuracy: 0.9994 - val_loss: 3.7070e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0565 - val_accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9969\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 173us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0399 - val_accuracy: 0.9979\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0117 - accuracy: 0.9995 - val_loss: 0.0385 - val_accuracy: 0.9969\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 178us/sample - loss: 0.0100 - accuracy: 0.9993 - val_loss: 1.7788e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4108e-08 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0620 - val_accuracy: 0.9928\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 6.9555e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 2.2855e-04 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0292 - val_accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 1s 171us/sample - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0413 - val_accuracy: 0.9969\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 1s 167us/sample - loss: 1.1756e-09 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 5.4034e-07 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9990\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 174us/sample - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0566 - val_accuracy: 0.9907\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 172us/sample - loss: 7.5554e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9979\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0128 - val_accuracy: 0.9990\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 174us/sample - loss: 8.4365e-08 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9959\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 177us/sample - loss: 1.5583e-09 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 1s 169us/sample - loss: 5.3421e-08 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9948\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 1.3669e-11 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9969\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 24316<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182448-6qlwesyu\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182448-6qlwesyu\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.07763</td></tr><tr><td>val_accuracy</td><td>0.9969</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1607019967</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▆█▅▇▂▂▁▁▁▂▁▆▃▅▂▂▁▂▃▁▃▅▂▄▃▁▄▄▃▁▁▁▂▁▁▂▂▁▁▁</td></tr><tr><td>accuracy</td><td>▃▄▅▁▇▇▇████▆▆▃▅▆█▇▆█▅▅▇▆▆▇▆▅▆███▇██▆████</td></tr><tr><td>val_loss</td><td>▂▇▁▁▁▁▁▁▁▁▁▁▃▅▂▁▁▁▁▅█▁▁▁▂▄▄▁▅▁▁▁▄▁▂▅▂▂▅▆</td></tr><tr><td>val_accuracy</td><td>▇▂█████████▇▇▇▇▇█▇▇▇▁███▆▇▆█▄██▇▆▇▇▃▇▆▇▆</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">dark-voice-54</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/6qlwesyu\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/6qlwesyu</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">true-monkey-55</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3bsvhrfx\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3bsvhrfx</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182610-3bsvhrfx</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 175us/sample - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.2338e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 1s 170us/sample - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 4.4824e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 178us/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 174us/sample - loss: 0.0114 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 178us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 7.8587e-08 - accuracy: 1.0000 - val_loss: 8.9387e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 1s 172us/sample - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 3.7202e-04 - accuracy: 0.9999 - val_loss: 0.0279 - val_accuracy: 0.9959\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 0.0031 - accuracy: 0.9998 - val_loss: 1.2302e-09 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 4.3507e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 176us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 179us/sample - loss: 3.5567e-07 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9886\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0093 - accuracy: 0.9999 - val_loss: 5.4768e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0030 - accuracy: 0.9998 - val_loss: 6.0403e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 6.4360e-04 - accuracy: 0.9999 - val_loss: 2.2695e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 6.9007e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 180us/sample - loss: 1.1340e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 7.9766e-04 - accuracy: 0.9998 - val_loss: 7.8734e-09 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 3.7867e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 6.4184e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 207us/sample - loss: 0.0024 - accuracy: 0.9998 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 204us/sample - loss: 9.0019e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 1.7821e-04 - accuracy: 0.9999 - val_loss: 3.6907e-10 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 3.3073e-04 - accuracy: 0.9998 - val_loss: 4.5863e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 4.6475e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 1.9137e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 2.4605e-10 - accuracy: 1.0000 - val_loss: 7.3814e-10 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 2.6509e-07 - accuracy: 1.0000 - val_loss: 4.1542e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 6.5807e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 2.3426e-04 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9979\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2230e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9990\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 4.1008e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 4.1268e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 6.5920e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 6.4285e-04 - accuracy: 0.9999 - val_loss: 5.2207e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 31056<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182610-3bsvhrfx\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182610-3bsvhrfx\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00064</td></tr><tr><td>accuracy</td><td>0.99989</td></tr><tr><td>val_loss</td><td>5e-05</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>83</td></tr><tr><td>_timestamp</td><td>1607020053</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▆▂▂▂▁▂█▂▄▄▁▃▂▁▇▃▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁</td></tr><tr><td>accuracy</td><td>▁▅▅▅▅▄▂▇▄▄▇▅▇█▇▅████▇█▄▅▇▅█████▇██▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>██████████▅██▁████████████████▇▇▇███████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">true-monkey-55</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3bsvhrfx\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/3bsvhrfx</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">lunar-smoke-56</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2fjesfsd\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2fjesfsd</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182738-2fjesfsd</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0053 - accuracy: 0.9995 - val_loss: 4.9209e-10 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 1.6767e-06 - accuracy: 1.0000 - val_loss: 8.6116e-10 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 1.0615e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 6.8346e-11 - accuracy: 1.0000 - val_loss: 2.3374e-09 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 2.8292e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 4.7812e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 3.0853e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 6.0730e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0021 - accuracy: 0.9999 - val_loss: 3.8033e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 202us/sample - loss: 0.0079 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 207us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 2.0914e-09 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0172 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 5.6083e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 4.7571e-04 - accuracy: 0.9999 - val_loss: 2.4411e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 4.2360e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0326 - val_accuracy: 0.9969\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0186 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 7.9667e-04 - accuracy: 0.9998 - val_loss: 1.3384e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 7.6118e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 4.9271e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 5.8886e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 2.0867e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 9.9730e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0035 - accuracy: 0.9995 - val_loss: 3.6907e-10 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 2.4861e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.8330e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 2.2376e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 2.7338e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 4.1008e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 2.4519e-06 - accuracy: 1.0000 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 1.3422e-08 - accuracy: 1.0000 - val_loss: 1.1254e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.7651e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 5.4937e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 1.5891e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 7.8186e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 1.3669e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 204us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 8.6116e-10 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 4.6937e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 31080<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182738-2fjesfsd\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182738-2fjesfsd\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00047</td></tr><tr><td>accuracy</td><td>0.99989</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>86</td></tr><tr><td>_timestamp</td><td>1607020145</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>40</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▃▆▂▁▁▁▁▁▁▁▂▂▂▇▁▂▂▃█▂▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>accuracy</td><td>▅▃▂▆████▇██▇▇▆▁▆▃▆▃▂▇███▆█▃▆▆▅████████▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>████████▆████████▁██████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">lunar-smoke-56</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2fjesfsd\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2fjesfsd</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">devoted-glitter-57</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/1y0s671y\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/1y0s671y</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_182908-1y0s671y</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 214us/sample - loss: 0.0059 - accuracy: 0.9999 - val_loss: 4.3095e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 5.4677e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 214us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 181us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 6.8346e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 4.5791e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 5.8778e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 9.4315e-09 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9979\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 1.7539e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 210us/sample - loss: 7.2153e-05 - accuracy: 1.0000 - val_loss: 1.8699e-08 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 208us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 216us/sample - loss: 8.2015e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 4.6905e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 204us/sample - loss: 4.6475e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 9.9785e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 2.0390e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0115 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 2.7338e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 8.9905e-07 - accuracy: 1.0000 - val_loss: 3.9367e-09 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 4.2189e-08 - accuracy: 1.0000 - val_loss: 2.0826e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0095 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 8.9132e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 28656<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_182908-1y0s671y\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_182908-1y0s671y\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00089</td></tr><tr><td>accuracy</td><td>0.99989</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>_timestamp</td><td>1607020235</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>45</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▄█▁▁▇▂</td></tr><tr><td>accuracy</td><td>▇███████████████▇████▇█▇█████████▇▇▁██▂▇</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">devoted-glitter-57</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/1y0s671y\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/1y0s671y</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">polar-serenity-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/icue1e7v\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/icue1e7v</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_183038-icue1e7v</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 2.5673e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 6.6158e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 2.7576e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 5.7340e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 1.7770e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 2.7338e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 5.1943e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 4.0280e-08 - accuracy: 1.0000 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 208us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 1.3226e-07 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9990\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 7.5588e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 1.2274e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 1.3669e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 7.1140e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 7.9951e-07 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9990\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0124 - accuracy: 0.9998 - val_loss: 8.6116e-10 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 2.5971e-10 - accuracy: 1.0000 - val_loss: 9.8381e-04 - val_accuracy: 0.9990\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 1.1017e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 7.0909e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 2.5278e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 204us/sample - loss: 6.2603e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 7.5043e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 5.1230e-04 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 2.7691e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 8.1672e-08 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9856\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 15788<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_183038-icue1e7v\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_183038-icue1e7v\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.2242</td></tr><tr><td>val_accuracy</td><td>0.98555</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>_timestamp</td><td>1607020325</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>17</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂▁▁▁▂▁▁▁▃▁▁</td></tr><tr><td>accuracy</td><td>█████▆▆█████████████████████▃▁███▃███▃▆█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_accuracy</td><td>███████████████████████▇██████▇███████▇▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">polar-serenity-58</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/icue1e7v\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/icue1e7v</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">confused-totem-59</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/f9d86e58\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/f9d86e58</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_183208-f9d86e58</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 215us/sample - loss: 0.0062 - accuracy: 0.9995 - val_loss: 3.0912e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 1.6403e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 1.4510e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 2.0094e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 1.3669e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 208us/sample - loss: 9.5685e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 9.0725e-04 - accuracy: 0.9999 - val_loss: 2.4605e-10 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 1.1076e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 2.0504e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 3.8992e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 4.1405e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 1.2279e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 208us/sample - loss: 2.2731e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 8.2601e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 1.3669e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 207us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 209us/sample - loss: 1.8485e-07 - accuracy: 1.0000 - val_loss: 1.6310e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 7.4302e-04 - accuracy: 0.9999 - val_loss: 1.0383e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 1.7166e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 1.0935e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 1.7085e-08 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9969\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 2.7338e-11 - accuracy: 1.0000 - val_loss: 6.2698e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0116 - val_accuracy: 0.9990\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 2.8485e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 2.0546e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 1.7223e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 2.3921e-09 - accuracy: 1.0000 - val_loss: 2.5467e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 7.6825e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 213us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 199us/sample - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 204us/sample - loss: 3.2677e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 208us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 185us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 6.8346e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 5.6821e-05 - accuracy: 1.0000 - val_loss: 3.5063e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 4.1008e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 1.9137e-10 - accuracy: 1.0000 - val_loss: 1.2302e-10 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2144e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 2360<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_183208-f9d86e58\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_183208-f9d86e58\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>_timestamp</td><td>1607020415</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>48</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▃▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁██▄█████████▃██████▆████████▆██████████</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>██████████████████████▁█████████████████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">confused-totem-59</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/f9d86e58\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/f9d86e58</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">apricot-flower-60</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/5lyr09gv\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/5lyr09gv</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_183338-5lyr09gv</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 2.2144e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 7.2447e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 7.7217e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 4.2375e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 205us/sample - loss: 3.8751e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 1.7770e-09 - accuracy: 1.0000 - val_loss: 1.5283e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 1.2302e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 1.9547e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 184us/sample - loss: 2.7338e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 5.9140e-07 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9990\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 7.5181e-10 - accuracy: 1.0000 - val_loss: 1.1012e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 3.0072e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 229us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 209us/sample - loss: 5.4677e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 215us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 202us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 195us/sample - loss: 1.3122e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 218us/sample - loss: 5.4677e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 245us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 210us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 207us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 2.4741e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.4677e-04 - val_accuracy: 0.9990\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 4.1694e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 34500<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_183338-5lyr09gv\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_183338-5lyr09gv\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>4e-05</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>88</td></tr><tr><td>_timestamp</td><td>1607020506</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>22</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▃▁▁▁▅▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>███▅███▅█████████▁██████████████████████</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>████████████████▁███████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">apricot-flower-60</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/5lyr09gv\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/5lyr09gv</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">swept-thunder-61</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2kddulfi\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2kddulfi</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_183511-2kddulfi</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8721 samples, validate on 969 samples\n",
      "Epoch 1/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 3.9911e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 7.6683e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "8721/8721 [==============================] - 2s 210us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 2.1500e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 1.9137e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "8721/8721 [==============================] - 2s 188us/sample - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 3.9703e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 4.5654e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8721/8721 [==============================] - 2s 193us/sample - loss: 4.2672e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8721/8721 [==============================] - 2s 201us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8721/8721 [==============================] - 2s 196us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8721/8721 [==============================] - 2s 186us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8721/8721 [==============================] - 2s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8721/8721 [==============================] - 2s 192us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 1.3669e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8721/8721 [==============================] - 2s 212us/sample - loss: 7.2465e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8721/8721 [==============================] - 2s 194us/sample - loss: 3.0072e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 9.5685e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 2.8705e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 0.0056 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 9.9257e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8721/8721 [==============================] - 2s 206us/sample - loss: 2.0527e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8721/8721 [==============================] - 2s 190us/sample - loss: 0.0085 - accuracy: 0.9993 - val_loss: 2.2759e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8721/8721 [==============================] - 2s 187us/sample - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8721/8721 [==============================] - 2s 191us/sample - loss: 2.9333e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 3.0129e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 1.2739e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8721/8721 [==============================] - 2s 189us/sample - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8721/8721 [==============================] - 2s 198us/sample - loss: 6.8303e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8721/8721 [==============================] - 2s 203us/sample - loss: 1.3616e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8721/8721 [==============================] - 2s 200us/sample - loss: 3.1029e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 27528<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_183511-2kddulfi\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_183511-2kddulfi\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_step</td><td>50</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>_timestamp</td><td>1607020598</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>best_epoch</td><td>41</td></tr><tr><td>Label_class</td><td>All Classes</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▅▁▁▁▁▁▁▁▁▂▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁█▅▁▁▅▂▁</td></tr><tr><td>accuracy</td><td>▇████████▇██▇█▇████████████████▇▇▁▅▇█▅▇█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">swept-thunder-61</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2kddulfi\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/2kddulfi</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.11 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">generous-haze-62</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments</a><br/>\n                Run page: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/zaa4z99g\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/zaa4z99g</a><br/>\n                Run data is saved locally in <code>wandb\\run-20201203_183646-zaa4z99g</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 33340<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb\\run-20201203_183646-zaa4z99g\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb\\run-20201203_183646-zaa4z99g\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">generous-haze-62</strong>: <a href=\"https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/zaa4z99g\" target=\"_blank\">https://wandb.ai/supervisedlearning/CNN%20All%20kf%20experiments/runs/zaa4z99g</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "A target array with shape (8721, 2) was passed for an output of shape (None, 10) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e02c2348fe49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{} All kf experiments'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_kf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_all_KF_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\GitProjects\\SupervisedLearningCW\\Tasks\\SupervisedLearning\\Experiments\\CNNExperments.py\u001b[0m in \u001b[0;36mrun_all_KF_experiments\u001b[1;34m(classifier, classifier_name, experiment_range, experiment_name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         train_s, test_s = run_KFold_experiment(classifier, X_train, y_train, cnn_model_name=classifier_name,\n\u001b[1;32m---> 59\u001b[1;33m                                                classes_desc=class_title, class_labels=class_labels, stratified=True, custom_name=experiment_name)\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitProjects\\SupervisedLearningCW\\Tasks\\SupervisedLearning\\Experiments\\CNNExperments.py\u001b[0m in \u001b[0;36mrun_KFold_experiment\u001b[1;34m(cnn_model, X, y, cnn_model_name, classes_desc, class_labels, stratified, balance_classes, n_splits, random_state, custom_name, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;31m#y_probs = cnn_model.prediction_proba(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitProjects\\SupervisedLearningCW\\Tasks\\SupervisedLearning\\NeuralNetworks\\Conv.py\u001b[0m in \u001b[0;36mbuild_classifier\u001b[1;34m(self, X, y, validation_data)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmented_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconventional_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitProjects\\SupervisedLearningCW\\Tasks\\SupervisedLearning\\NeuralNetworks\\Conv.py\u001b[0m in \u001b[0;36mconventional_training\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    119\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                            callbacks=[self.wandb_callback()])\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclear_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2487\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2489\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001b[1;32m~\\.conda\\envs\\suplearn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    808\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    809\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (8721, 2) was passed for an output of shape (None, 10) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "experiment = '{} All kf experiments'.format(classifier_name)\n",
    "all_kf = ce.run_all_KF_experiments(classifier, classifier_name=classifier_name, experiment_name=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('suplearn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f669ade7ac486071bd60c2fa29ee3295826785883e735477c7c16f13d8637a87"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}